{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "* Due: 24.1.2019 at noon\n",
    "* Max points: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General rules\n",
    "* Send the source code or the written notes of your answers as an attachment to jussi.hakanen@jyu.fi before the due time\n",
    "* You will get feedback about your answers a week from the due date\n",
    "* From the second week on, the exercises will be given on the previous Wednesday's lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "For all of the following problems, we study optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\qquad & x_1^2+x_2^2 + x_1+2x_2\\\\\n",
    "\\text{s.t.}\\qquad &x_1,x_2\\in\\mathbb R\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. **(2 points)** Implement a steepest descent algorithm, but do a golden section search to each new search direction. This means that you need to define a single-variable function to determine the step length. Set the length of the interval for doing line search as parameter of the method. Solve above problem using your method.\n",
    "2. **(3 points)** Plot the steps of the steepest descent algorithm implemented at the class (with fixed step lengths) against the steps of a steepest descent algorithm that you implemented above. You can choose any starting point you wish, but not the optimum.\n",
    "3. **(3 points)** Implement the Quasi-Newton method with DFP update as described e.g., at https://en.wikipedia.org/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula. Solve above problem using this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57686508 -1.07281955]\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import ad\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2 + x[1]**2 + x[0] + 2*x[1]\n",
    "\n",
    "#Step length function to find step\n",
    "def step_length(f):\n",
    "    step = 0\n",
    "    L=0.001\n",
    "    while(f<L):\n",
    "        step = f - L\n",
    "    return step\n",
    "\n",
    "def golden_section(f):\n",
    "    return ad.gh(f)\n",
    "\n",
    "#steepest descent function\n",
    "def steepest(f,start,step,precision):\n",
    "    steps = []\n",
    "    x = np.array(start)\n",
    "    f_old = float('inf')\n",
    "    f_new = f(x)\n",
    "    d = float('inf') #search direction\n",
    "    while abs(f_old-f_new)>precision:\n",
    "        f_old = f_new\n",
    "        d = -np.array(golden_section(f)[0](x))\n",
    "        x = x+d*step\n",
    "        f_new = f(x)\n",
    "        steps.append(list(x))\n",
    "    return x,f_new,steps\n",
    "    \n",
    "\n",
    "start = [-10,-10]\n",
    "(x_value,f_value,steps) = steepest(f,start,.02,0.001)\n",
    "print(x_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
